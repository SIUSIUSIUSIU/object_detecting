{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqpm32oeZCNY",
        "outputId": "23107504-033f-400c-b3d3-68a625140d6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLzHAWAyFFTa"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 바운딩 박스를 칠 선의 색을 결정\n",
        "# np.random.uniform(0, 255, size = (class 개수, 3))\n",
        "\n",
        "colors = np.random.uniform(0, 255 , size=(2,3))"
      ],
      "metadata": {
        "id": "EAcdSOavVACi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 객체 label (클래스명) 이 저장된 파일 경로\n",
        "label_path = \"Your Path\""
      ],
      "metadata": {
        "id": "4PZdm5G4Uwl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#학습된 레이블을 저장할 리스트\n",
        "classes = []\n",
        "\n",
        "#label_path의 파일을 열어서 f에 저장\n",
        "with open(label_path, 'r') as f:\n",
        "    #for line in f.readlines() : 파일을 1줄씩 읽어서 f에 저장\n",
        "    #line.strip():줄바꿈 탭등을 제거하고 리턴\n",
        "    classes = [line.strip() for line in f.readlines()]\n"
      ],
      "metadata": {
        "id": "17l7E10AUg21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94PS8vlC7H3n",
        "outputId": "868bc99d-ba21-4a47-af27-2bf921b7b457"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['empty', 'full']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#yolo 학습 weight 경로\n",
        "weight_path = 'Your Path'\n",
        "#yolo 설정 경로\n",
        "config_path =  'Your Path'"
      ],
      "metadata": {
        "id": "W1wrUpNAUlXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cv2.dnn.readNetFromDarknet () : yolo 객체 탐지 객체를 리턴\n",
        "net = cv2.dnn.readNetFromDarknet(config_path, weight_path)\n",
        "#GPU 사용 설정\n",
        "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
        "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)"
      ],
      "metadata": {
        "id": "u3Q_PNPaUp-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#net.getLayerNames() : yolo 탐지 객체의 레이어 이름을 리턴\n",
        "layer_names = net.getLayerNames()\n",
        "\n",
        "#for i in net.getUnconnectedOutLayers() :\n",
        "#  yolo에서 객체 탐지를 수행하는 3개의 레이어 인덱스를 리턴\n",
        "#  맨앞에 input 레이어가 포함된 인덱스이기 때문에 실제로는 -1 한값을 사용해야함\n",
        "\n",
        "#layer_names[i - 1]  : layer_names (yolo의 레이어 이름이 저장되 있음) 에서\n",
        "#                      yolo의 객체 탐지 레이어의 이름을 리턴\n",
        "\n",
        "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
        "output_layers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pd59aFqQU5hj",
        "outputId": "92558ded-2587-48b3-8afd-d267ef8afecf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['yolo_139', 'yolo_150', 'yolo_161']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vid_size[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6j07XAzKyhSY",
        "outputId": "4de8b338-3431-4bca-9f5f-88e10b8e39bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1920"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#비디오 파일 경로\n",
        "file_name = 'Youre FileName'\n",
        "\n",
        "#클래스에 속할 확률이 0.5 이상 인 경우만 출력\n",
        "min_confidence = 0.5\n",
        "#비디오 파일을 읽어서 리턴할 객체\n",
        "cap = cv2.VideoCapture(file_name)\n",
        "video_output_path = '/content/detect_result.mp4'\n",
        "# 저장할 비디오 파일의 코덱 \n",
        "codec = cv2.VideoWriter_fourcc(*'XVID')\n",
        "\n",
        "#비디오 화면 크기\n",
        "#cv2.CAP_PROP_FRAME_WIDTH : file_name 비디오 프레임의 가로\n",
        "#cv2.CAP_PROP_FRAME_HEIGHT) : file_name 비디오 프레임의 세로\n",
        "vid_size = (round(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
        "\n",
        "#file_name 비디오의 초당 프레임\n",
        "vid_fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "#cv2.VideoWriter : 비디오 파일을 생성해서 저장할 객체 생성\n",
        "#cv2.VideoWriter(저장할 경로, 비디오코덱, 비디오 초당 프레임, 프레임크기)    \n",
        "vid_writer = cv2.VideoWriter(video_output_path, codec, vid_fps, vid_size) \n",
        "\n",
        "frame_num = 1\n",
        "while True:\n",
        "    #비디오 한프레임을 파일을 읽어서 리턴\n",
        "    # ret : 비디오 한 프레임을 정상적으로 읽는데 성공하면 True\n",
        "    #                                            실패하면 False 리턴\n",
        "    #frame : 비디오 한 프레임의 이미지 \n",
        "    ret, frame = cap.read()\n",
        "    if frame is None:\n",
        "        break\n",
        "\n",
        "    # 1초마다 frame에서 객체 검출\n",
        "    # if frame_num % int(vid_fps) == 0:\n",
        "    print(\"=\"*100)\n",
        "    # print(\"frame read\")\n",
        "    print(f'frame num: {frame_num}')\n",
        "    #비디오 캡쳐 프레임을 img에 복사\n",
        "    img = frame.copy()\n",
        "    #이미지의 높이 너비를 대입\n",
        "    height,width,channel = img.shape\n",
        "\n",
        "    #cv2.dnn.blobFromImage : yolo의 입력 이미지 객체 생성\n",
        "    \n",
        "    #cv2.dnn.blobFromImage(원본이미지 (비디오 프레임)\n",
        "    #                     , 이미지에 곱할값 ,\n",
        "    #                     (yolo학습 이미지 높이 , yolo학습 이미지 너비),\n",
        "    #                     원본이미지 RGB에서 빼줄 값,\n",
        "    #                     R과B를 바꿀지 여부 openCV로 읽었기 때문에 BGR이므로 바꿔야함\n",
        "    #                     )\n",
        "    blob = cv2.dnn.blobFromImage(img, 1/255 , (608, 608), (0, 0, 0), True)\n",
        "    #blob을 Object Detect할 준비를 함\n",
        "    net.setInput(blob)\n",
        "    # print(\"object detect start\")\n",
        "    #net.forward(output_layers) : Object Detect를 수행하고 결과를 리턴\n",
        "    outs = net.forward(output_layers)\n",
        "    # print(\"object detect end\")\n",
        "\n",
        "    #검출된 클래스의 아이디를 저장할 객체\n",
        "    class_ids = []\n",
        "    #검출된 클래스의 확률을 저장할 객체\n",
        "    confidences = []\n",
        "    #검출된 bounding box를 저장할 객체\n",
        "    boxes = []\n",
        "\n",
        "    #outs에 저장된 yolo output layer 3개의 객체 검출 결과를 차례로 out에 저장\n",
        "    for layer_index, out in enumerate(outs):\n",
        "        #out에 저장된 layer들의 객체 검출 결과를 detection에 저장\n",
        "        for detect_index,detection in enumerate(out):\n",
        "\n",
        "            # 검출된 객체가 어떤 클래스에 속하는지 확률\n",
        "            scores = detection[5:]\n",
        "            #np.argmax(scores) : 확률이 가장 높은 인덱스를 리턴        \n",
        "            class_id = np.argmax(scores)\n",
        "            #class_id (확률이 가장 높은 인덱스) \n",
        "            #scores[class_id] : 확률의 최대값 리턴\n",
        "            confidence = scores[class_id]\n",
        "\n",
        "            # 확률이 min_confidence (0.5) 이상일때\n",
        "            if confidence > min_confidence:\n",
        "                # detection에 저장된 box의 정보는 0~1 사이 값이기 때문에\n",
        "                # 이미지의 너비와 높이를 곱해줘서 실제 좌표로 변환\n",
        "                # bounding box의 center x 좌표\n",
        "                center_x = int(detection[0] * width)\n",
        "                # bounding box의 center y 좌표\n",
        "                center_y = int(detection[1] * height)\n",
        "                # bounding box의 가로 크기\n",
        "                w = int(detection[2] * width)\n",
        "                # bounding box의 세로 크기\n",
        "                h = int(detection[3] * height)\n",
        "\n",
        "                # bounding box의 x좌표\n",
        "                x = int(center_x - w / 2)\n",
        "                # bounding box의 y좌표\n",
        "                y = int(center_y - h / 2)\n",
        "\n",
        "                #검출된 bounding box의 x좌표, y좌표,가로,세로를\n",
        "                #저장함\n",
        "                boxes.append([x, y, w, h])\n",
        "                #검출된 객체의 확률을 저장함\n",
        "                confidences.append(float(confidence))\n",
        "                #검출된 객체가 어떤 클래스에 속하는지를 저장\n",
        "                class_ids.append(class_id)\n",
        "\n",
        "        \n",
        "    #cv2.dnn.NMSBoxes() : 조건에 일치하는 bounding box의 인덱스를 리턴 \n",
        "    #                   : 특정확률 이상의 bounding box\n",
        "    #                   : 2 개 bounding box 가 겹쳤을때 \n",
        "    #                   : 두 bounding box 간 특정 IOU 이상의 bouding box \n",
        "    #                     (더 큰 bounding box의 IOU가 크다) 리턴\n",
        "\n",
        "    #cv2.dnn.NMSBoxes(bounding box 좌표들, 확률, IOU값)\n",
        "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, min_confidence, 0.4)\n",
        "\n",
        "    #indexes : 조건에 일치하는 bounding box의 인덱스\n",
        "    #indexes에서 하나씩 i에 대입\n",
        "    for i in indexes:\n",
        "        #bounding box 의 x좌표 y좌표 width height를 대입\n",
        "        x, y, w, h = boxes[i]\n",
        "        if x+w > vid_size[0] or y+h > vid_size[1]: continue\n",
        "        #bounding box가 어떤 클래스에 속하는지 대입\n",
        "        class_id = class_ids[i]\n",
        "        #클래스의 레이블 대입\n",
        "        label = str(classes[class_id])\n",
        "        #클래스의 색 대입\n",
        "        color = colors[class_id]\n",
        "        #이미지에 사각형 추가\n",
        "        #cv2.rectangle(\n",
        "        #    사각형추가할 이미지, (left,top), (right, bottom), 사각형색, 사각형두께)\n",
        "        cv2.rectangle(img, (x, y), (x + w, y + h), color, 1)\n",
        "        #이미지에 텍스트 추가\n",
        "        #cv2.putText(텍스트추가할 이미지,텍스트,\n",
        "        #            (left, top), 폰트, 글자크기 , 색, 선두께)\n",
        "        cv2.putText(img, label, (x, y + 20), cv2.FONT_HERSHEY_TRIPLEX, 1 , color, 2) \n",
        "    \n",
        "    #img를 비디오파일에 저장\n",
        "    vid_writer.write(img)\n",
        "    # print(\"frame video save ok\")\n",
        "\n",
        "    # print(\"=\"*100)      \n",
        "    frame_num += 1\n",
        "\n",
        "\n",
        "print(\"frame vide save end\")\n",
        "print(\"=\"*100)\n",
        "#출력 비디오 파일 닫기\n",
        "vid_writer.release()\n",
        "#입력 비디오 파일 닫기\n",
        "cap.release()"
      ],
      "metadata": {
        "id": "nbs0GE1NUQtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDQxDtpr-tDH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "bd1dd50e-4ca0-4d67-849a-e5b4ef94594e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1fcad538-29f0-4795-aa49-93beebb6a909\", \"detect_result.mp4\", 85374290)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(video_output_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UK5yAKHhrgKF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}